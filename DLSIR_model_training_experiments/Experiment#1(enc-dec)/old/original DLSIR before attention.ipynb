{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"original DLSIR before attention.ipynb","version":"0.3.2","provenance":[{"file_id":"1zsYQ1V32dLGkXvbdVp6AG8JTP-bS96UP","timestamp":1551604911970},{"file_id":"1ursszJhFcltPAA40vFIEJL4wMRgK-ROp","timestamp":1551027864380}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"WP_MksUeLWMn","colab_type":"code","outputId":"0591cd11-4fa4-4c08-99ab-c19be2dcb4a9","executionInfo":{"status":"ok","timestamp":1551602686014,"user_tz":-330,"elapsed":1751,"user":{"displayName":"Sumanth S Rao","photoUrl":"https://lh6.googleusercontent.com/-lBPhFWivFMg/AAAAAAAAAAI/AAAAAAAAICQ/ieEPM1BlS80/s64/photo.jpg","userId":"11552248322616800750"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["'''\n","Author : Parasharaaaaa\n","'''"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nAuthor : Parasharaaaaa\\n'"]},"metadata":{"tags":[]},"execution_count":1}]},{"metadata":{"id":"yclzM55J9eWS","colab_type":"code","colab":{}},"cell_type":"code","source":["from __future__ import absolute_import, division, print_function"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-mJLfBtZ9oMk","colab_type":"code","outputId":"593ebefc-6c74-4284-ea12-d7034cbac1d1","executionInfo":{"status":"ok","timestamp":1551602702077,"user_tz":-330,"elapsed":2097,"user":{"displayName":"Sumanth S Rao","photoUrl":"https://lh6.googleusercontent.com/-lBPhFWivFMg/AAAAAAAAAAI/AAAAAAAAICQ/ieEPM1BlS80/s64/photo.jpg","userId":"11552248322616800750"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import tensorflow as tf\n","\n","tf.enable_eager_execution()\n","tf.__version__"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.13.1'"]},"metadata":{"tags":[]},"execution_count":3}]},{"metadata":{"id":"51wzXN45D_wK","colab_type":"code","outputId":"711883df-d228-4be8-fe2b-43d285bbd57e","executionInfo":{"status":"ok","timestamp":1551602704229,"user_tz":-330,"elapsed":1515,"user":{"displayName":"Sumanth S Rao","photoUrl":"https://lh6.googleusercontent.com/-lBPhFWivFMg/AAAAAAAAAAI/AAAAAAAAICQ/ieEPM1BlS80/s64/photo.jpg","userId":"11552248322616800750"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["from tensorflow.keras.layers import Bidirectional,CuDNNGRU,CuDNNLSTM,GRU,LSTM,concatenate,Dense,Input,Embedding\n","from tensorflow.keras.layers import  multiply, Flatten\n","from tensorflow.keras.layers import Lambda, Masking\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import plot_model\n","from hyperopt import Trials, STATUS_OK, tpe,  fmin, tpe, hp, STATUS_OK, Trials\n","import importlib\n","from keras import backend as K"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"Khm9fpB0u1-E","colab_type":"code","outputId":"5b63ff00-b88c-44d8-f400-4bb02aaca5e5","executionInfo":{"status":"ok","timestamp":1551337871431,"user_tz":-330,"elapsed":10010,"user":{"displayName":"Parashara Ramesh","photoUrl":"https://lh4.googleusercontent.com/-O9JVlBlcs0k/AAAAAAAAAAI/AAAAAAAAFBs/9qv0idIOgGg/s64/photo.jpg","userId":"02206828966354294918"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"cell_type":"code","source":["!pip install h5py\n","\n","!apt-get install -y libhdf5-dev"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.8.0)\n","Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.14.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.11.0)\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","libhdf5-dev is already the newest version (1.10.0-patch1+docs-4).\n","0 upgraded, 0 newly installed, 0 to remove and 10 not upgraded.\n"],"name":"stdout"}]},{"metadata":{"id":"PkLwVo2Bu2Tf","colab_type":"code","colab":{}},"cell_type":"code","source":["import h5py"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hDfhdQAT9ywv","colab_type":"code","colab":{}},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Scikit-learn includes many helpful utilities\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","\n","import re\n","import numpy as np\n","import os\n","import time\n","import json\n","from glob import glob\n","from PIL import Image\n","import pickle"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AaJDX82i-Aao","colab_type":"text"},"cell_type":"markdown","source":["## Download and prepare the MS-COCO dataset"]},{"metadata":{"id":"ZHwBnQ_e92Ac","colab_type":"code","outputId":"ef759dc7-3dca-4d35-88d8-5e9f9b95ceab","executionInfo":{"status":"ok","timestamp":1551603276229,"user_tz":-330,"elapsed":560657,"user":{"displayName":"Sumanth S Rao","photoUrl":"https://lh6.googleusercontent.com/-lBPhFWivFMg/AAAAAAAAAAI/AAAAAAAAICQ/ieEPM1BlS80/s64/photo.jpg","userId":"11552248322616800750"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"cell_type":"code","source":["annotation_zip = tf.keras.utils.get_file('captions.zip', \n","                                          cache_subdir=os.path.abspath('.'),\n","                                          origin = 'http://images.cocodataset.org/annotations/annotations_trainval2014.zip',\n","                                          extract = True)\n","annotation_file = os.path.dirname(annotation_zip)+'/annotations/captions_train2014.json'\n","\n","name_of_zip = 'train2014.zip'\n","if not os.path.exists(os.path.abspath('.') + '/' + name_of_zip):\n","  image_zip = tf.keras.utils.get_file(name_of_zip, \n","                                      cache_subdir=os.path.abspath('.'),\n","                                      origin = 'http://images.cocodataset.org/zips/train2014.zip',\n","                                      extract = True)\n","  PATH = os.path.dirname(image_zip)+'/train2014/'\n","else:\n","  PATH = os.path.abspath('.')+'/train2014/'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading data from http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n","252878848/252872794 [==============================] - 27s 0us/step\n","Downloading data from http://images.cocodataset.org/zips/train2014.zip\n","13510574080/13510573713 [==============================] - 363s 0us/step\n"],"name":"stdout"}]},{"metadata":{"id":"BHEUm75H-ZPX","colab_type":"text"},"cell_type":"markdown","source":["## Optionally, limit the size of the training set for faster training"]},{"metadata":{"id":"HcpZkwJy-FNL","colab_type":"code","colab":{}},"cell_type":"code","source":["# read the json file\n","with open(annotation_file, 'r') as f:\n","    annotations = json.load(f)\n","\n","# storing the captions and the image name in vectors\n","all_captions = []# only has the captions\n","all_img_name_vector = []# only has the paths\n","\n","for annot in annotations['annotations']:\n","    caption = '<start> ' + annot['caption'] + ' <end>'\n","    image_id = annot['image_id']\n","    full_coco_image_path = PATH + 'COCO_train2014_' + '%012d.jpg' % (image_id)\n","    \n","    all_img_name_vector.append(full_coco_image_path)\n","    all_captions.append(caption)\n","\n","# shuffling the captions and image_names together\n","# setting a random state\n","train_captions, img_name_vector = shuffle(all_captions,\n","                                          all_img_name_vector,\n","                                          random_state=1)\n","\n","# selecting the first 10000 captions from the shuffled set\n","num_examples = 2000\n","train_captions = train_captions[:num_examples]\n","img_name_vector = img_name_vector[:num_examples]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zgO5Ar0plvRU","colab_type":"code","outputId":"c06210be-96b2-4e2d-84d2-5d9652424e29","executionInfo":{"status":"ok","timestamp":1551348746565,"user_tz":-330,"elapsed":948,"user":{"displayName":"Parashara Ramesh","photoUrl":"https://lh4.googleusercontent.com/-O9JVlBlcs0k/AAAAAAAAAAI/AAAAAAAAFBs/9qv0idIOgGg/s64/photo.jpg","userId":"02206828966354294918"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"cell_type":"code","source":["img_name_vector[:5]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/train2014/COCO_train2014_000000324909.jpg',\n"," '/content/train2014/COCO_train2014_000000511972.jpg',\n"," '/content/train2014/COCO_train2014_000000508809.jpg',\n"," '/content/train2014/COCO_train2014_000000270497.jpg',\n"," '/content/train2014/COCO_train2014_000000008014.jpg']"]},"metadata":{"tags":[]},"execution_count":60}]},{"metadata":{"id":"0Lppokp0AB4S","colab_type":"text"},"cell_type":"markdown","source":["## Preprocess the images using InceptionV3"]},{"metadata":{"id":"rjBTXJ8G-0WP","colab_type":"code","colab":{}},"cell_type":"code","source":["def load_image(image_path):\n","    img = tf.io.read_file(image_path)\n","    img = tf.image.decode_jpeg(img, channels=3)\n","    img = tf.image.resize(img, (299, 299))\n","    img = tf.keras.applications.inception_v3.preprocess_input(img)\n","    return img, image_path"],"execution_count":0,"outputs":[]},{"metadata":{"id":"piLUiUP_AUZ1","colab_type":"text"},"cell_type":"markdown","source":["## Initialize InceptionV3 and load the pretrained Imagenet weights"]},{"metadata":{"id":"GrxomNXZATia","colab_type":"code","outputId":"9a6b163b-d3e4-44fc-e608-2201ba5bfd3d","executionInfo":{"status":"ok","timestamp":1551603438377,"user_tz":-330,"elapsed":13978,"user":{"displayName":"Sumanth S Rao","photoUrl":"https://lh6.googleusercontent.com/-lBPhFWivFMg/AAAAAAAAAAI/AAAAAAAAICQ/ieEPM1BlS80/s64/photo.jpg","userId":"11552248322616800750"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"cell_type":"code","source":["image_model = tf.keras.applications.InceptionV3(include_top=False, \n","                                                weights='imagenet')\n","new_input = image_model.input\n","hidden_layer = image_model.layers[-1].output\n","\n","image_features_extract_model = tf.keras.Model(new_input, hidden_layer)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","87916544/87910968 [==============================] - 3s 0us/step\n"],"name":"stdout"}]},{"metadata":{"id":"azLRIVAVPrOW","colab_type":"text"},"cell_type":"markdown","source":["**Code to cache the inceptionV3  tensors**\n","\n","---\n","\n"]},{"metadata":{"id":"-qz62J7hP9ED","colab_type":"code","colab":{}},"cell_type":"code","source":["'''experimental stuff!!'''\n","'''\n","https://github.com/tensorflow/tensorflow/issues/25731\n","https://github.com/tensorflow/tensorflow/issues/25808\n","'''\n","\n","\n","# getting the unique images\n","encode_train = sorted(set(img_name_vector))\n","\n","# feel free to change the batch_size according to your system configuration\n","# a generator which yields 16 images at one shot along with its path\n","image_dataset = tf.data.Dataset.from_tensor_slices(\n","                                encode_train).map(load_image).batch(16)\n","\n","for img, path in image_dataset:\n","  #image_features_extract_model is the InceptionV3 stack which gives out tensors in the end \n","  batch_features = image_features_extract_model(img)\n","  batch_features = tf.reshape(batch_features, \n","                              (batch_features.shape[0], -1, batch_features.shape[3]))\n","  \n","  #   #for the eager tensor apparently wrapping it using np.array works which you can use instead of .numpy()\n","  #   batch_features= np.array(batch_features)\n","  #   print(batch_features)\n","  #this is the workaround for the path.numpy\n","  #   utfdecoder = lambda t: t.decode('utf-8')\n","  #   utffunc = np.vectorize(utfdecoder)\n","  #   path_of_features = utffunc(path.numpy())  \n","\n","  for bf, p in zip(batch_features, path):\n","    path_of_feature = p.numpy().decode(\"utf-8\")\n","    np.save(path_of_feature, bf.numpy())\n","  \n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"SmZS2N0bXG3T","colab":{}},"cell_type":"code","source":["# loading the numpy files \n","def map_func(cap,img_name):\n","  #caching the features stored in the .npy files\n","  image_tensor = np.load(img_name.numpy().decode('utf-8') +'.npy')\n","  return cap.numpy(), image_tensor\n","\n","#old code for non caching of features\n","#   batch_features = image_features_extract_model(tf.expand_dims(load_image(img_name)[0], axis = 0))\n","#   image_tensor = tf.reshape(batch_features, (batch_features.shape[0], -1, batch_features.shape[3]))\n","#   image_tensor = tf.squeeze(image_tensor)\n","\n","  \n","          "],"execution_count":0,"outputs":[]},{"metadata":{"id":"zr9hZnOIAmcN","colab_type":"text"},"cell_type":"markdown","source":["## Preprocess and tokenize the captions"]},{"metadata":{"colab_type":"code","id":"HZfK8RhQRPFj","colab":{}},"cell_type":"code","source":["# This will find the maximum length of any caption in our dataset\n","def calc_max_length(tensor):\n","    return max(len(t) for t in tensor)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"oJGE34aiRPFo","colab":{}},"cell_type":"code","source":["# The steps above is a general process of dealing with text processing\n","# choosing the top 5000 words from the vocabulary\n","top_k = 5000\n","tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=top_k, \n","                                                  oov_token=\"<unk>\", \n","                                                  filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')\n","tokenizer.fit_on_texts(train_captions)\n","train_seqs = tokenizer.texts_to_sequences(train_captions)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"8Q44tNQVRPFt","colab":{}},"cell_type":"code","source":["tokenizer.word_index['<pad>'] = 0"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"0fpJb5ojRPFv","colab":{}},"cell_type":"code","source":["# creating the tokenized vectors\n","train_seqs = tokenizer.texts_to_sequences(train_captions)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"AidglIZVRPF4","colab":{}},"cell_type":"code","source":["# padding each vector to the max_length of the captions\n","# if the max_length parameter is not provided, pad_sequences calculates that automatically\n","cap_vector = tf.keras.preprocessing.sequence.pad_sequences(train_seqs, padding='post')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UuJ4uyKqNdkk","colab_type":"code","outputId":"ce0a097a-5a52-4dd9-da60-286e1298b5a1","executionInfo":{"status":"ok","timestamp":1551603664294,"user_tz":-330,"elapsed":1599,"user":{"displayName":"Sumanth S Rao","photoUrl":"https://lh6.googleusercontent.com/-lBPhFWivFMg/AAAAAAAAAAI/AAAAAAAAICQ/ieEPM1BlS80/s64/photo.jpg","userId":"11552248322616800750"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["cap_vector.shape\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2000, 40)"]},"metadata":{"tags":[]},"execution_count":17}]},{"metadata":{"colab_type":"code","id":"gL0wkttkRPGA","outputId":"57f9ffd3-4b59-4c0e-9760-74fe797472e6","executionInfo":{"status":"ok","timestamp":1551603669721,"user_tz":-330,"elapsed":1234,"user":{"displayName":"Sumanth S Rao","photoUrl":"https://lh6.googleusercontent.com/-lBPhFWivFMg/AAAAAAAAAAI/AAAAAAAAICQ/ieEPM1BlS80/s64/photo.jpg","userId":"11552248322616800750"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# calculating the max_length \n","# used to store the attention weights\n","max_length = calc_max_length(train_seqs)\n","max_length"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["40"]},"metadata":{"tags":[]},"execution_count":18}]},{"metadata":{"colab_type":"text","id":"M3CD75nDpvTI"},"cell_type":"markdown","source":["## Split the data into training and testing"]},{"metadata":{"colab_type":"code","id":"iS7DDMszRPGF","colab":{}},"cell_type":"code","source":["# Create training and validation sets using 80-20 split\n","img_name_train, img_name_val, cap_train, cap_val = train_test_split(img_name_vector, \n","                                                                    cap_vector, \n","                                                                    test_size=0.2, \n","                                                                    random_state=0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sctNrXcnHIbV","colab_type":"text"},"cell_type":"markdown","source":["**MODEL HYPERPARAMETERS AND CONFIG PARAMS**"]},{"metadata":{"colab_type":"code","id":"Q3TnZ1ToRPGV","colab":{}},"cell_type":"code","source":["# feel free to change these parameters according to your system's configuration\n","\n","BATCH_SIZE = 8\n","BUFFER_SIZE = 1000\n","embedding_dim = 256\n","units = 512\n","vocab_size = len(tokenizer.word_index)\n","# shape of the vector extracted from InceptionV3 is (64, 2048)\n","# these two variables represent that\n","features_shape = 2048\n","attention_features_shape = 64\n","\n","model_config = {\n","    'save_dir': '../saved_models',\n","    'dim_cnn': 4096,\n","    'optimizer': 'adam',\n","    'batch_size': BATCH_SIZE,\n","    'epoch': 2,\n","    'output_dim': 1024,\n","    'dim_word': 300,\n","    'lrate': 0.05,\n","    #'lrate': 0.0005,\n","    'max_cap_length' : max_length,\n","    'margin': 0.05, #alpha\n","    'glove.path': '../data/glove.6B.300d.txt'\n","}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vTEhdTraHSim","colab_type":"text"},"cell_type":"markdown","source":["**CREATING THE DATASET GENERATOR USING tf.data.Dataset**"]},{"metadata":{"colab_type":"code","id":"FDF_Nm3tRPGZ","colab":{}},"cell_type":"code","source":["#create a simple datagenerator using the coco image features and the captions\n","def create_data_generator():\n","  dataset = tf.data.Dataset.from_tensor_slices((cap_train,img_name_train))\n","\n","  # using map to load the numpy files in parallel\n","  # NOTE: Be sure to set num_parallel_calls to the number of CPU cores you have\n","  # https://www.tensorflow.org/api_docs/python/tf/py_func\n","  dataset = dataset.map(lambda item1, item2: tf.py_function(\n","            map_func, [item1, item2], [tf.int32, tf.float32]), num_parallel_calls=8)\n","\n","  # shuffling and batching\n","  dataset = dataset.shuffle(BUFFER_SIZE)\n","  # https://www.tensorflow.org/api_docs/python/tf/contrib/data/batch_and_drop_remainder\n","  dataset = dataset.batch(BATCH_SIZE)\n","  dataset = dataset.repeat()\n","  dataset = dataset.prefetch(1)\n","\n","  return dataset\n","  \n","  \n","  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"LJSZF44BNTm4","colab_type":"code","colab":{}},"cell_type":"code","source":["#using the above data_generator to yield training data to be fitted to the model at training time\n","def train_generator():\n","  train_iter = create_data_generator().make_one_shot_iterator()\n","  while True:\n","    caps, imgs = train_iter.get_next()\n","    batch = [caps.numpy(),imgs.numpy()]\n","    dummy = np.zeros(shape=(BATCH_SIZE, model_config['output_dim'] * 2))    \n","    yield batch, dummy\n","    \n","\n","def test_generator():\n","  train_iter = create_data_generator(cap_val, img_name_val).make_one_shot_iterator()\n","  while True:\n","    caps, imgs = train_iter.get_next()\n","    batch = [caps.numpy(),imgs.numpy()]\n","    dummy = np.zeros(shape=(BATCH_SIZE, model_config['output_dim'] * 2))    \n","    yield batch, dummy\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ISmDf4BWB-0Y","colab_type":"text"},"cell_type":"markdown","source":["**TESTING THE DATASET GENERATOR**"]},{"metadata":{"id":"XDG29NsSCC0j","colab_type":"code","outputId":"f819ac5d-4afe-4c71-9cf3-f84581cb4309","executionInfo":{"status":"error","timestamp":1551603685949,"user_tz":-330,"elapsed":1327,"user":{"displayName":"Sumanth S Rao","photoUrl":"https://lh6.googleusercontent.com/-lBPhFWivFMg/AAAAAAAAAAI/AAAAAAAAICQ/ieEPM1BlS80/s64/photo.jpg","userId":"11552248322616800750"}},"colab":{"base_uri":"https://localhost:8080/","height":214}},"cell_type":"code","source":["iterator = create_data_generator().make_one_shot_iterator()\n","x,y = next(iterator)\n","print(x.shape)\n","print(y.shape)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-87090a373f83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_data_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_one_shot_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: create_data_generator() missing 2 required positional arguments: 'cap' and 'img_name'"]}]},{"metadata":{"id":"Uo1-LFdoC7FQ","colab_type":"text"},"cell_type":"markdown","source":["##Model"]},{"metadata":{"id":"8qBSelVruhHB","colab_type":"code","colab":{}},"cell_type":"code","source":["#A GRU WRAPPER\n","def gru(units):\n","  # If you have a GPU, we recommend using the CuDNNGRU layer (it provides a \n","  # significant speedup).\n","  if tf.test.is_gpu_available():\n","    return CuDNNGRU(units, \n","                    return_sequences=False, \n","                    return_state=False, \n","                    recurrent_initializer='glorot_uniform')\n","  else:\n","    return GRU(units, \n","                 return_sequences=False, \n","                 return_state=True, \n","                 recurrent_activation='sigmoid', \n","                 recurrent_initializer='glorot_uniform')\n","\n","#RELATED TO LOSS FUNCTIONS\n","def compute_errors(s_emb, im_emb):\n","    \"\"\" Given sentence and image embeddings, compute the error matrix \"\"\"\n","    errors = [order_violations(x, y) for x in s_emb for y in im_emb]\n","    return np.asarray(errors).reshape((len(s_emb), len(im_emb)))\n","\n","def order_violations(s, im):\n","    \"\"\" \n","    Computes the order violations (Equation 2 in the paper) \n","    i.e this is the similiarity score -S(c,i)\n","    \"\"\"\n","    \n","    return np.power(np.linalg.norm(s - im),2)\n","\n","\n","def l2norm(X):\n","    \"\"\" Compute L2 norm, row-wise \"\"\"\n","    norm = tf.reduce_sum(tf.sqrt(tf.pow(X, 2)), 1)\n","    X /= norm[:, None]\n","    return X\n","\n","\n","\n","def contrastive_loss(labels, predict):\n","    \"\"\"For a minibatch of sentence and image embeddings, compute the pairwise contrastive loss, refer the original report to understand this better\"\"\"\n","    global model_options\n","    margin = model_config['margin']\n","    predict = tf.identity(predict)\n","    s, im = tf.split(predict, [model_config['output_dim'], model_config['output_dim']], axis = -1)\n","    print(\"s=\",s)\n","    print(\"im=\",im)\n","\n","    im2 = tf.expand_dims(im,axis=0)\n","    s2 = tf.expand_dims(s,axis=1)\n","    print(\"im2=\",im2)\n","    print(\"s2=\",s2)\n","\n","    errors = tf.reduce_sum(tf.pow(tf.subtract(im2, s2), 2), 2)\n","    diagonal = tf.diag_part(errors)\n","    cost_s = tf.maximum(tf.constant(0, dtype=tf.float32), tf.add(tf.subtract(margin, errors), diagonal))\n","    diagonal2 = tf.reshape(diagonal, [-1, 1])\n","    print(\"\\n\\n\\n\\n\")\n","    # print(\"margin.shape = \", margin.shape)\n","    print(\"errors.shape = \", errors.shape)\n","    print(\"diagonal.shape = \", diagonal.shape)\n","    print(\"diagonal2.shape = \", diagonal2.shape)\n","    print(\"\\n\\n\\n\\n\")\n","    cost_im = tf.maximum(tf.constant(0, dtype=tf.float32), tf.add(tf.subtract(margin, errors), diagonal2))\n","    cost_tot = tf.add(cost_s, cost_im)\n","    print(\"cost_s=\",cost_s)\n","    print(\"cost_im=\",cost_im)\n","    print(\"cost_tot before=\",cost_tot)\n","    zeroes = tf.zeros((model_config['batch_size'],), tf.float32)\n","    print(\"zeroes=\",zeroes)\n","    cost_tot = tf.linalg.set_diag(cost_tot, zeroes)\n","    print(\"cost_tot after=\",cost_tot)\n","    return tf.reduce_sum(cost_tot)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"B5oAybhmhGqM","colab_type":"code","colab":{}},"cell_type":"code","source":["#for evaluating the model, look at this shit carefully!!\n","def contrastive_loss_cap(labels,predict):\n","  s = tf.identity(predict)\n","  pass\n","\n","def contrastive_loss_img(labels,predict):\n","  im = tf.identity(predict)\n","  pass"],"execution_count":0,"outputs":[]},{"metadata":{"id":"W_t0HwTLIwYo","colab_type":"text"},"cell_type":"markdown","source":["**MODEL DEFINITION**"]},{"metadata":{"id":"XYdoJM_xGXgB","colab_type":"code","outputId":"510f40c1-6990-403d-f908-29ec873778ff","executionInfo":{"status":"ok","timestamp":1551603709110,"user_tz":-330,"elapsed":1222,"user":{"displayName":"Sumanth S Rao","photoUrl":"https://lh6.googleusercontent.com/-lBPhFWivFMg/AAAAAAAAAAI/AAAAAAAAICQ/ieEPM1BlS80/s64/photo.jpg","userId":"11552248322616800750"}},"colab":{"base_uri":"https://localhost:8080/","height":459}},"cell_type":"code","source":["#IMAGE SIDE (DECODER SIDE)\n","print(\"image model loading...\")\n","image_input = Input(shape=(64, 2048), name='image_input')\n","X = Flatten()(image_input)\n","X = Dense(model_config['output_dim'])(X)\n","emb_image = Lambda(lambda x: l2norm(x))(X)   #the final embedding representation of the image\n","\n","#CAPTION SIDE (ENCODER SIDE)\n","print (\"Text model loading..\")\n","cap_input = Input(shape=(model_config['max_cap_length'],), dtype='float32', name='cap_input')\n","X = Masking(mask_value=0,input_shape=(model_config['max_cap_length'], model_config['output_dim']))(X)\n","# from scratch\n","X = Embedding(output_dim=model_config['dim_word'], input_dim=len(tokenizer.word_index), input_length=model_config['max_cap_length'])(cap_input)\n","# pretrained GloVe\n","# X = Embedding(output_dim=model_config['dim_word'], input_dim=len(worddict)+2, input_length=model_config['max_cap_length'], weights=[embedding_matrix], trainable=True)(cap_input)\n","X = gru(model_config['output_dim'])(X)\n","emb_cap = Lambda(lambda x: l2norm(x))(X)   #the final embedding representation of the catption\n","\n","#CONCATENATING BOTH MODAL REPRESENTATIONS\n","print (\"loading the joined model\")\n","merged = concatenate([emb_cap, emb_image])\n","\n","#MODEL INPUT/OUTPUT DEFINTION\n","model = Model(inputs=[cap_input, image_input], outputs=[merged])\n","\n","#MODEL COMPILING STEP\n","print (\"compiling the model\")\n","model.compile(optimizer=model_config['optimizer'], loss=contrastive_loss)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["image model loading...\n","Text model loading..\n","loading the joined model\n","compiling the model\n","s= Tensor(\"loss/concatenate_2_loss/split:0\", shape=(?, 1024), dtype=float32)\n","im= Tensor(\"loss/concatenate_2_loss/split:1\", shape=(?, 1024), dtype=float32)\n","im2= Tensor(\"loss/concatenate_2_loss/ExpandDims:0\", shape=(1, ?, 1024), dtype=float32)\n","s2= Tensor(\"loss/concatenate_2_loss/ExpandDims_1:0\", shape=(?, 1, 1024), dtype=float32)\n","\n","\n","\n","\n","\n","errors.shape =  (?, ?)\n","diagonal.shape =  (?,)\n","diagonal2.shape =  (?, 1)\n","\n","\n","\n","\n","\n","cost_s= Tensor(\"loss/concatenate_2_loss/Maximum:0\", shape=(?, ?), dtype=float32)\n","cost_im= Tensor(\"loss/concatenate_2_loss/Maximum_1:0\", shape=(?, ?), dtype=float32)\n","cost_tot before= Tensor(\"loss/concatenate_2_loss/Add_2:0\", shape=(?, ?), dtype=float32)\n","zeroes= Tensor(\"loss/concatenate_2_loss/zeros:0\", shape=(8,), dtype=float32)\n","cost_tot after= Tensor(\"loss/concatenate_2_loss/MatrixSetDiag:0\", shape=(?, ?), dtype=float32)\n"],"name":"stdout"}]},{"metadata":{"id":"HjwtgoyaKv_-","colab_type":"text"},"cell_type":"markdown","source":["**MODEL ARCHITECTURE SUMMARY**"]},{"metadata":{"id":"csQoDxqTISs7","colab_type":"code","outputId":"df23c4a0-a996-4270-fdf1-2d96fa74a213","executionInfo":{"status":"ok","timestamp":1551338292355,"user_tz":-330,"elapsed":411550,"user":{"displayName":"Parashara Ramesh","photoUrl":"https://lh4.googleusercontent.com/-O9JVlBlcs0k/AAAAAAAAAAI/AAAAAAAAFBs/9qv0idIOgGg/s64/photo.jpg","userId":"02206828966354294918"}},"colab":{"base_uri":"https://localhost:8080/","height":460}},"cell_type":"code","source":["model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","cap_input (InputLayer)          (None, 40)           0                                            \n","__________________________________________________________________________________________________\n","image_input (InputLayer)        (None, 64, 2048)     0                                            \n","__________________________________________________________________________________________________\n","embedding (Embedding)           (None, 40, 300)      692400      cap_input[0][0]                  \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 131072)       0           image_input[0][0]                \n","__________________________________________________________________________________________________\n","cu_dnngru (CuDNNGRU)            (None, 1024)         4073472     embedding[0][0]                  \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 1024)         134218752   flatten[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 1024)         0           cu_dnngru[0][0]                  \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 1024)         0           dense[0][0]                      \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 2048)         0           lambda_1[0][0]                   \n","                                                                 lambda[0][0]                     \n","==================================================================================================\n","Total params: 138,984,624\n","Trainable params: 138,984,624\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"03c5JUI0xOZN","colab_type":"text"},"cell_type":"markdown","source":["**LOAD THE SAVED MODEL WEIGHTS BEFORE RETRAINING**"]},{"metadata":{"id":"JSWejUzshebX","colab_type":"code","outputId":"23733b58-319c-4c5c-8aeb-bc7a86883829","executionInfo":{"status":"ok","timestamp":1551338378893,"user_tz":-330,"elapsed":493613,"user":{"displayName":"Parashara Ramesh","photoUrl":"https://lh4.googleusercontent.com/-O9JVlBlcs0k/AAAAAAAAAAI/AAAAAAAAFBs/9qv0idIOgGg/s64/photo.jpg","userId":"02206828966354294918"}},"colab":{"base_uri":"https://localhost:8080/","height":224}},"cell_type":"code","source":["#Setup between colab and drive and fuse or something!!\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n","!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":0,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","Selecting previously unselected package google-drive-ocamlfuse.\n","(Reading database ... 131322 files and directories currently installed.)\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.1-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n","Setting up google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"metadata":{"id":"hWwiK1GUxNrR","colab_type":"code","outputId":"9c1f1a59-9315-4554-98b0-5e37aaf9bc51","executionInfo":{"status":"ok","timestamp":1551338537923,"user_tz":-330,"elapsed":9243,"user":{"displayName":"Parashara Ramesh","photoUrl":"https://lh4.googleusercontent.com/-O9JVlBlcs0k/AAAAAAAAAAI/AAAAAAAAFBs/9qv0idIOgGg/s64/photo.jpg","userId":"02206828966354294918"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["#load from model.json and try stuff...\n","from tensorflow.keras.models import model_from_json\n","# load json and create model\n","with open('drive/DLSIR_model_weights/model.json', 'r') as json_file:\n","  loaded_model_json = json_file.read()\n","loaded_model = model_from_json(loaded_model_json)\n","# load weights into new model\n","loaded_model.load_weights(\"drive/DLSIR_model_weights/model_weights.h5\")\n","model = loaded_model\n","print(\"Loaded model from disk\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loaded model from disk\n"],"name":"stdout"}]},{"metadata":{"id":"NXjp6RPjyiJs","colab_type":"code","outputId":"20f01bda-29a1-48e5-e945-15946261b01e","executionInfo":{"status":"ok","timestamp":1551338537924,"user_tz":-330,"elapsed":8608,"user":{"displayName":"Parashara Ramesh","photoUrl":"https://lh4.googleusercontent.com/-O9JVlBlcs0k/AAAAAAAAAAI/AAAAAAAAFBs/9qv0idIOgGg/s64/photo.jpg","userId":"02206828966354294918"}},"colab":{"base_uri":"https://localhost:8080/","height":392}},"cell_type":"code","source":["#recompile this loaded model\n","model.compile(optimizer=model_config['optimizer'], loss=contrastive_loss)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["s= Tensor(\"loss_2/concatenate_2_loss/split:0\", shape=(?, 1024), dtype=float32)\n","im= Tensor(\"loss_2/concatenate_2_loss/split:1\", shape=(?, 1024), dtype=float32)\n","im2= Tensor(\"loss_2/concatenate_2_loss/ExpandDims:0\", shape=(1, ?, 1024), dtype=float32)\n","s2= Tensor(\"loss_2/concatenate_2_loss/ExpandDims_1:0\", shape=(?, 1, 1024), dtype=float32)\n","\n","\n","\n","\n","\n","errors.shape =  (?, ?)\n","diagonal.shape =  (?,)\n","diagonal2.shape =  (?, 1)\n","\n","\n","\n","\n","\n","cost_s= Tensor(\"loss_2/concatenate_2_loss/Maximum:0\", shape=(?, ?), dtype=float32)\n","cost_im= Tensor(\"loss_2/concatenate_2_loss/Maximum_1:0\", shape=(?, ?), dtype=float32)\n","cost_tot before= Tensor(\"loss_2/concatenate_2_loss/Add_2:0\", shape=(?, ?), dtype=float32)\n","zeroes= Tensor(\"loss_2/concatenate_2_loss/zeros:0\", shape=(8,), dtype=float32)\n","cost_tot after= Tensor(\"loss_2/concatenate_2_loss/MatrixSetDiag:0\", shape=(?, ?), dtype=float32)\n"],"name":"stdout"}]},{"metadata":{"id":"Zfpzq_LVK2ox","colab_type":"text"},"cell_type":"markdown","source":["**TIME TO FIT THE DATA AND TRAIN THE MODEL!**"]},{"metadata":{"id":"dDsVVSTdprye","colab_type":"code","colab":{}},"cell_type":"code","source":["# #model.fit\n","# #to do write code to save checkpoints of model weights\n","# train_hist = model.fit(train_generator(), batch_size = BATCH_SIZE, steps_per_epoch=(len(cap_train) // BATCH_SIZE),verbose=1,epochs = 2) "],"execution_count":0,"outputs":[]},{"metadata":{"id":"pAbaZHl--uu9","colab_type":"code","outputId":"a1323d26-b759-49e4-adcb-320e87ba646e","executionInfo":{"status":"ok","timestamp":1551604093982,"user_tz":-330,"elapsed":361513,"user":{"displayName":"Sumanth S Rao","photoUrl":"https://lh6.googleusercontent.com/-lBPhFWivFMg/AAAAAAAAAAI/AAAAAAAAICQ/ieEPM1BlS80/s64/photo.jpg","userId":"11552248322616800750"}},"colab":{"base_uri":"https://localhost:8080/","height":462}},"cell_type":"code","source":["#fitgenerator\n","train_gen = train_generator()\n","train_hist = model.fit_generator(train_gen, steps_per_epoch=(len(cap_train) // BATCH_SIZE),verbose=1,epochs = 10)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["200/200 [==============================] - 39s 194ms/step - loss: 5.6000\n","Epoch 2/10\n","200/200 [==============================] - 36s 179ms/step - loss: 5.6000\n","Epoch 3/10\n","200/200 [==============================] - 36s 179ms/step - loss: 5.6000\n","Epoch 4/10\n","200/200 [==============================] - 36s 179ms/step - loss: 5.5993\n","Epoch 5/10\n","200/200 [==============================] - 36s 179ms/step - loss: 5.5201\n","Epoch 6/10\n","200/200 [==============================] - 36s 179ms/step - loss: 5.3565\n","Epoch 7/10\n","200/200 [==============================] - 36s 179ms/step - loss: 5.1950\n","Epoch 8/10\n","200/200 [==============================] - 36s 179ms/step - loss: 5.0338\n","Epoch 9/10\n","200/200 [==============================] - 36s 179ms/step - loss: 4.8875\n","Epoch 10/10\n","200/200 [==============================] - 36s 179ms/step - loss: 4.7945\n"],"name":"stdout"}]},{"metadata":{"id":"KprIxaGChZJ3","colab_type":"text"},"cell_type":"markdown","source":["**SAVE THE WEIGHTS INTO DRIVE AND BACK**"]},{"metadata":{"id":"vuUE47uuu0Mv","colab_type":"code","outputId":"62e73445-15ba-46bd-e4c3-402673bdf1cd","executionInfo":{"status":"error","timestamp":1551604093984,"user_tz":-330,"elapsed":352165,"user":{"displayName":"Sumanth S Rao","photoUrl":"https://lh6.googleusercontent.com/-lBPhFWivFMg/AAAAAAAAAAI/AAAAAAAAICQ/ieEPM1BlS80/s64/photo.jpg","userId":"11552248322616800750"}},"colab":{"base_uri":"https://localhost:8080/","height":231}},"cell_type":"code","source":["#save the weights\n","model_json = model.to_json()\n","with open(\"drive/DLSIR_model_weights/model.json\", \"w\") as json_file:\n","    json_file.write(model_json)\n","# serialize weights to HDF5\n","model.save_weights(\"drive/DLSIR_model_weights/model_weights.h5\")\n","print(\"Saved model to drive\")"],"execution_count":0,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-b12dbe916200>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drive/DLSIR_model_weights/model.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# serialize weights to HDF5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drive/DLSIR_model_weights/model_weights.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/DLSIR_model_weights/model.json'"]}]},{"metadata":{"id":"Rnz_kk7yLnMF","colab_type":"text"},"cell_type":"markdown","source":["**LOOK AT THE MODEL WEIGHTS AND SEE STUFF**\n","\n"]},{"metadata":{"id":"vBOCGKuLLktg","colab_type":"code","colab":{}},"cell_type":"code","source":[" weights = model.get_weights()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zSOSEwZ8LtbM","colab_type":"code","outputId":"ace536bc-81dc-46b3-b3b2-0cb1d2e3e239","executionInfo":{"status":"ok","timestamp":1551347272569,"user_tz":-330,"elapsed":724,"user":{"displayName":"Parashara Ramesh","photoUrl":"https://lh4.googleusercontent.com/-O9JVlBlcs0k/AAAAAAAAAAI/AAAAAAAAFBs/9qv0idIOgGg/s64/photo.jpg","userId":"02206828966354294918"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"cell_type":"code","source":["for i in range(len(weights)):\n","  print(weights[i].shape)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(2308, 300)\n","(300, 3072)\n","(1024, 3072)\n","(6144,)\n","(131072, 1024)\n","(1024,)\n"],"name":"stdout"}]},{"metadata":{"id":"nfDw8P0iGKN0","colab_type":"text"},"cell_type":"markdown","source":["**EVALUATION HELPER FUNCTIONS**"]},{"metadata":{"id":"y4MPxjw0Ltdv","colab_type":"code","colab":{}},"cell_type":"code","source":["def input2image(c2i):\n","    \"\"\"\n","    Input caption->Images (Image Search)\n","    c2i: (1, N) vector of caption to image errors\n","    returns indices of 10 most likely pictures\n","    \"\"\"\n","    \n","    inds = np.zeros(c2i.shape, dtype='int32')\n","    \n","    for i in range(c2i.shape[0]):\n","        inds[i,:] = np.argsort(c2i[i,:])\n","    \n","    return inds[:,0:10]\n","\n","def t2i(c2i):\n","    \"\"\"\n","    Text->Images (Image Search)\n","    c2i: (5N, N) matrix of caption to image errors\n","    vis_details: if true, return a dictionary for ROC visualization purposes\n","    \"\"\"\n","\n","    ranks = np.zeros(c2i.shape[0])\n","\n","    for i in range(len(ranks)):\n","        d_i = c2i[i]\n","        inds = np.argsort(d_i)\n","\n","        rank = np.where(inds == int(i/5))[0][0]\n","        ranks[i] = rank\n","\n","        def image_dict(k):\n","            return {'id': k, 'score': float(d_i[k])}\n","\n","    r10 = 100.0 * len(np.where(ranks < 10)[0]) / len(ranks)\n","    meanr = ranks.mean() + 1\n","\n","    stats = map(float, [r10, meanr])\n","\n","    return stats\n","\n","\n","\n","def i2t(c2i):\n","    \"\"\"\n","    Text->Images (Image Search)\n","    c2i: (5N, N) matrix of caption to image errors\n","    \"\"\"\n","\n","    ranks = np.zeros(c2i.shape[1])\n","\n","    for i in range(len(ranks)):\n","        d_i = c2i[:, i]\n","        inds = np.argsort(d_i)\n","\n","        rank = np.where((inds/5).astype(int) == i)[0][0]\n","        ranks[i] = rank\n","\n","    # Compute metrics\n","    r10 = 100.0 * len(np.where(ranks < 10)[0]) / len(ranks)\n","    meanr = ranks.mean() + 1\n","    return map(float, [r10, meanr])\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hvglCaebLtjw","colab_type":"code","colab":{}},"cell_type":"code","source":["def eval_model():\n","  #have to look at this shit carefully and look \n","  weights = model.get_weights()\n","\n","  emb_w = weights[0]\n","  im_w = weights[4]\n","  im_b = weights[5]\n","  gru_weights = weights[1:4]\n","\n","  test_model_im = Model(inputs=image_input, outputs=emb_image)\n","  test_model_im.set_weights([im_w, im_b])\n","  test_model_im.compile(optimizer='adam', loss=\"mse\")#contrastive_loss)\n","  test_model_cap = Model(inputs=cap_input, outputs=emb_cap)\n","  test_model_cap.set_weights([emb_w]+ gru_weights)\n","  test_model_cap.compile(optimizer='adam', loss=\"mse\")#contrastive_loss)\n","\n","  #have to look at this shit!\n","  test_cap, test_im = test_iter.all()\n","\n","  pred_cap = test_model_cap.predict(test_cap)\n","  pred_im = test_model_im.predict(test_im)\n","  test_errs = compute_errors(pred_cap, pred_im)\n","\n","  r10_c, rmean_c = t2i(test_errs)\n","  r10_i, rmean_i = i2t(test_errs)\n","  print (\"Image to text: %.1f %.1f\" % (r10_i, rmean_i))\n","  print (\"Text to image: %.1f %.1f\" % (r10_c, rmean_c))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UIsXxBVMLtmc","colab_type":"code","outputId":"934b5d46-c561-43fd-8e68-922780e689c6","executionInfo":{"status":"error","timestamp":1551348063243,"user_tz":-330,"elapsed":1717,"user":{"displayName":"Parashara Ramesh","photoUrl":"https://lh4.googleusercontent.com/-O9JVlBlcs0k/AAAAAAAAAAI/AAAAAAAAFBs/9qv0idIOgGg/s64/photo.jpg","userId":"02206828966354294918"}},"colab":{"base_uri":"https://localhost:8080/","height":333}},"cell_type":"code","source":["eval_model()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-58-676841fa0ed8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-57-0f623a1ae7dd>\u001b[0m in \u001b[0;36meval_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mtest_model_cap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#contrastive_loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0mtest_cap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_im\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0mall_caps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_cap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_cap_length'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mall_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_cap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dim_cnn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'test_iter' is not defined"]}]},{"metadata":{"id":"lkXrnfr3Ltqa","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"7gYRiOPzLtui","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"f1_ngmCTLtxf","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"10kxTPzjLttY","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"pOBFXcMDLtpP","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"vxcxz0P9Lthq","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"YERY8JA1Ltgp","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}